modelname:  pervasive

model : pervasive
start_from : 0
start_from_best : 1

encoder:
  type : none
  input_dim : 128
  input_dropout : .2
  encode_position : 0
  encode_length : 0
 
decoder:
  type : none
  input_dim : 128
  input_dropout : .2
  encode_position : 0
  encode_length : 0
  tie_target_weights : 1
  copy_source_weights : 0
  prediction_dropout : .2

 
network :
  type: densenet
  growth_rate : 32
  num_layers: 20
  divide_channels : 2
  normalize_channels : 0
  kernels : 3
  dilation : 1
  groups : 1
  layer_type: regular
  transition_type : 1
  bias : 0
  gated : 0
  weigth_norm : 0
  init_weights: 0
  conv_dropout : 0.2
  efficient : 1

aggregator:
  mode : max
  first_aggregator : max
  attention_dropout : .2
  scale_ctx : 1
  nonlin : none 
  mapping: linear
  map_embeddings : none
  aggr_dim : 3


loss:
  version : ml  # tok , seq
  normalize : ntokens
  penalize_confidence : 0

data:
  src : de
  trg : en
  dir : data/iwslt
  batch_size: 16
  max_src_length : 70
  max_trg_length : 70

optim: 
  reset : 1
  seed : 1
  LR:
      base : 0.001
      decay_start : 0
      decay_every: 10
      decay_rate : 0.5
      patience : 2
      criterion : loss
      schedule : step
  # Scheudled sampling
  SS:
      start : -1
      limit_vocab : 0
      speed : 100
      increase_every : 5
      increase_prob : 0.05
      schedule : step

  num_batches : 1
  max_epochs : 35
  solver : adam
  alpha : 0.9
  beta : .999
  epsilon : 1e-8
  weight_decay : 0
  amsgrad : 0
  grad_clip : 1
  nesterov : 0

track :
  batch_size : 32
  split : val
  max_length: 80
  max_length_a : 0
  max_length_b : 80
  log_every : 200
  checkpoint : 5000
  beam_size : 1
  forbid_unk : 1
  all_metrics : 1
  verbose : 0

